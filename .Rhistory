}
return(b_split)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
# Determine the best split over all of the attributes at a certain node
get.split <- function(x_row, y, nfeat, minleaf) {
x <- train_data[x_row, ]
b_gini <- -999
b_split <- NULL
predictors <- sample(ncol(x), nfeat)
for (i in predictors){
split <- best.split(x[,i], x_row, y, minleaf)
if (is.null(split)) next
gini <- unlist(split[1])
# The best split is the split with best reduction
if (gini > b_gini){
b_gini <- gini
b_split <- append('attribute'= i,split[2:4])
}
}
return(b_split)
}
tree.grow <- function(x_row, y, nmin, minleaf, nfeat){
attribute_names = colnames(train_data)
root <- Node$new('start', dataX = x_row, dataY = y)
nodelist <- list(root)
print(nodelist)
while(length(nodelist) > 0) {
node <- nodelist[[1]]
nodelist[[1]] <- NULL
if (impurity.gini(node$dataY) > 0 && length(node$dataX) > nmin) {
split <- get.split(node$dataX, node$dataY, nfeat, minleaf)
print(split)
left_y <- y[left_data]
right_y <- y[right_data]
node$Set(splitAttribute = attribute_names[split$attribute], splitValue = split$best_splitpoint)
leftchild <- node$AddChild('leftChild', dataX = split$left_data, dataY = left_y)
rightchild <- node$AddChild('rightChild', dataX = split$right_data, dataY = right_y)
nodelist <- append(nodelist, list(leftchild, rightchild))
} else {
to.leaf(node)
}
}
return(root)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
# Determine the best split over all of the attributes at a certain node
get.split <- function(x_row, y, nfeat, minleaf) {
x <- train_data[x_row, ]
b_gini <- -999
b_split <- NULL
predictors <- sample(ncol(x), nfeat)
for (i in predictors){
split <- best.split(x[,i], x_row, y, minleaf)
if (is.null(split)) next
gini <- unlist(split[1])
# The best split is the split with best reduction
if (gini > b_gini){
b_gini <- gini
b_split <- append(list('attribute'= i),split[2:4])
}
}
return(b_split)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
tree.grow <- function(x_row, y, nmin, minleaf, nfeat){
attribute_names = colnames(train_data)
root <- Node$new('start', dataX = x_row, dataY = y)
nodelist <- list(root)
print(nodelist)
while(length(nodelist) > 0) {
node <- nodelist[[1]]
nodelist[[1]] <- NULL
if (impurity.gini(node$dataY) > 0 && length(node$dataX) > nmin) {
split <- get.split(node$dataX, node$dataY, nfeat, minleaf)
print(split)
left_y <- y[left_data]
right_y <- y[right_data]
node$Set(splitAttribute = attribute_names[split$attribute], splitValue = split$best_splitpoint)
leftchild <- node$AddChild('leftChild', dataX = split$left_split, dataY = left_y)
rightchild <- node$AddChild('rightChild', dataX = split$right_split, dataY = right_y)
nodelist <- append(nodelist, list(leftchild, rightchild))
} else {
to.leaf(node)
}
}
return(root)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
tree.grow <- function(x_row, y, nmin, minleaf, nfeat){
attribute_names = colnames(train_data)
root <- Node$new('start', dataX = x_row, dataY = y)
nodelist <- list(root)
print(nodelist)
while(length(nodelist) > 0) {
node <- nodelist[[1]]
nodelist[[1]] <- NULL
if (impurity.gini(node$dataY) > 0 && length(node$dataX) > nmin) {
split <- get.split(node$dataX, node$dataY, nfeat, minleaf)
left_y <- y[split$left_split]
right_y <- y[split$right_split]
node$Set(splitAttribute = attribute_names[split$attribute], splitValue = split$best_splitpoint)
leftchild <- node$AddChild('leftChild', dataX = split$left_split, dataY = left_y)
rightchild <- node$AddChild('rightChild', dataX = split$right_split, dataY = right_y)
nodelist <- append(nodelist, list(leftchild, rightchild))
} else {
to.leaf(node)
}
}
return(root)
}
# Determine the best split over all of the attributes at a certain node
get.split <- function(x_row, y, nfeat, minleaf) {
x <- train_data[x_row, ]
b_gini <- -999
b_split <- NULL
predictors <- sample(ncol(x), nfeat)
for (i in predictors){
split <- best.split(x[,i], x_row, y, minleaf)
if (is.null(split)) next
gini <- unlist(split[1])
# The best split is the split with best reduction
if (gini > b_gini){
b_gini <- gini
b_split <- append(list('attribute'= i),split[2:4])
}
}
return(b_split)
}
to.leaf <- function(node) {
node$Set(label = mode(node$dataY))
}
tree.grow <- function(x_row, y, nmin, minleaf, nfeat){
attribute_names = colnames(train_data)
root <- Node$new('start', dataX = x_row, dataY = y)
nodelist <- list(root)
print(nodelist)
while(length(nodelist) > 0) {
node <- nodelist[[1]]
nodelist[[1]] <- NULL
if (impurity.gini(node$dataY) > 0 && length(node$dataX) > nmin) {
split <- get.split(node$dataX, node$dataY, nfeat, minleaf)
left_y <- y[split$left_split]
right_y <- y[split$right_split]
node$Set(splitAttribute = attribute_names[split$attribute], splitValue = split$best_splitpoint)
leftchild <- node$AddChild('leftChild', dataX = split$left_split, dataY = left_y)
rightchild <- node$AddChild('rightChild', dataX = split$right_split, dataY = right_y)
nodelist <- append(nodelist, list(leftchild, rightchild))
} else {
to.leaf(node)
}
}
return(root)
}
tree.classify <- function(data, tr) {
y <- NULL
for (i in 1:nrow(data)) {
node <- tr
while(!isLeaf(node)) {
if (data[i, node$splitAttribute] > node$splitValue) {
node <- node$leftChild
} else {
node <- node$rightChild
}
}
y[i] <- node$label
}
return(y)
}
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c()
for (i in 1:m) {
samples <- sample(x_row, x_row, TRUE)
trees <- append(trees, tree.grow(samples, y[samples], nmin, minleaf, nfeat))
}
return(trees)
}
tree.classify.bag <- function(data, tr) {
labels <- matrix( nrow=nrow(data), ncol=length(tr))
predictions <- c()
for (i in 1:length(tr)) {
labels[,i] <- tree.classify(data, tr[[i]])
}
for(i in 1:nrow(labels)) {
predictions[i] <- sum(labels[i,])>(0.5*length(labels[i,]))
}
return(predictions)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
print(tree_1, 'splitValue', "splitAttribute")
tree.grow <- function(x_row, y, nmin, minleaf, nfeat){
attribute_names = colnames(train_data)
root <- Node$new('start', dataX = x_row, dataY = y)
nodelist <- list(root)
print(nodelist)
while(length(nodelist) > 0) {
node <- nodelist[[1]]
nodelist[[1]] <- NULL
if (impurity.gini(node$dataY) > 0 && length(node$dataX) > nmin) {
split <- get.split(node$dataX, node$dataY, nfeat, minleaf)
print(split)
left_y <- y[split$left_split]
right_y <- y[split$right_split]
node$Set(splitAttribute = attribute_names[split$attribute], splitValue = split$best_splitpoint)
leftchild <- node$AddChild('leftChild', dataX = split$left_split, dataY = left_y)
rightchild <- node$AddChild('rightChild', dataX = split$right_split, dataY = right_y)
nodelist <- append(nodelist, list(leftchild, rightchild))
} else {
to.leaf(node)
}
}
return(root)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
tree.grow <- function(x_row, y, nmin, minleaf, nfeat){
attribute_names = colnames(train_data)
root <- Node$new('start', dataX = x_row, dataY = y)
nodelist <- list(root)
print(nodelist)
while(length(nodelist) > 0) {
node <- nodelist[[1]]
nodelist[[1]] <- NULL
if (impurity.gini(node$dataY) > 0 && length(node$dataX) > nmin) {
split <- get.split(node$dataX, node$dataY, nfeat, minleaf)
print(split)
left_y <- y[split$left_split]
right_y <- y[split$right_split]
node$Set(splitAttribute = attribute_names[split$attribute], splitValue = split$best_splitpoint)
leftchild <- node$AddChild('leftChild', dataX = split$left_split, dataY = left_y)
rightchild <- node$AddChild('rightChild', dataX = split$right_split, dataY = right_y)
nodelist <- append(nodelist, list(leftchild, rightchild))
print(nodelist)
} else {
to.leaf(node)
}
}
return(root)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
tree.grow <- function(x_row, y, nmin, minleaf, nfeat){
attribute_names = colnames(train_data)
root <- Node$new('start', dataX = x_row, dataY = y)
nodelist <- list(root)
print(nodelist)
while(length(nodelist) > 0) {
node <- nodelist[[1]]
nodelist[[1]] <- NULL
if (impurity.gini(node$dataY) > 0 && length(node$dataX) > nmin) {
split <- get.split(node$dataX, node$dataY, nfeat, minleaf)
print(split)
left_y <- y[split$left_split]
right_y <- y[split$right_split]
print(left_y)
node$Set(splitAttribute = attribute_names[split$attribute], splitValue = split$best_splitpoint)
leftchild <- node$AddChild('leftChild', dataX = split$left_split, dataY = left_y)
rightchild <- node$AddChild('rightChild', dataX = split$right_split, dataY = right_y)
nodelist <- append(nodelist, list(leftchild, rightchild))
} else {
to.leaf(node)
}
}
return(root)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
print(train_classes)
train_classes <- as.integer(train_data[,3] > 0 )
print(train_classes)
# Load in training and test data
train_data <- read.csv2("./eclipse-metrics-packages-2.0.csv")
View(train_data)
# Load in training and test data
train_data <- read.csv2("./eclipse-metrics-packages-2.0.csv")
test_data <- read.csv2("./eclipse-metrics-packages-3.0.csv")
train_classes <- as.integer(train_data[,4] > 0 )
test_classes <- test_data[,4] > 0
print(train_classes)
# Take relevant columns from data
train_data <- train_data[,c(3, 5:45)]
test_data <- test_data[,c(3, 5:45)]
for (col in 1:ncol(train_data)){
train_data[,col] <- as.numeric(as.character(train_data[,col]))
test_data[,col] <- as.numeric(as.character(test_data[,col]))
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
print(tree_1, 'splitValue', "splitAttribute")
predictions_1 <- tree.classify(test_data, tree_1)
measures_1 <- measures(test_classes, predictions_1)
print(measures_1)
print(table(predictions_1, test_classes))
source('C:/Users/Lisa/Desktop/UU/Data_Mining_2019/Assignment_1_code.R', echo=TRUE)
source('C:/Users/Lisa/Desktop/UU/Data_Mining_2019/Assignment_1_code.R', echo=TRUE)
print(predictions_2)
print(trees_1[[1]], "splitValue", 'splitAttribute')
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
# Prints the tree in the correct way
print(tree_1, 'splitValue', "splitAttribute")
# Multiple times grows a tree using tree.grow and stores them in a list
#   x_row: The row numbers of the dataset
#   y: The class labels of the dataset
#   nmin: The minimm length of the data in a node to not be a leaf node.
#   minleaf: The minimum number of datapoints that needs to be in a node to not be a leafnode
#   nfeat: The number of features that need to be sampled from the dataset
#   m: The number of trees that need to be grown
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c()
for (i in 1:m) {
# Sample  from the rows of x to create a distinct datasets
samples <- sample(x_row, x_row, TRUE)
print(tree.grow(samples, y[samples], nmin, minleaf, nfeat))
break
# Give the samples to tree.grow as the row numbers of the dataset
trees[i] <- tree.grow(samples, y[samples], nmin, minleaf, nfeat)
}
return(trees)
}
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
# Multiple times grows a tree using tree.grow and stores them in a list
#   x_row: The row numbers of the dataset
#   y: The class labels of the dataset
#   nmin: The minimm length of the data in a node to not be a leaf node.
#   minleaf: The minimum number of datapoints that needs to be in a node to not be a leafnode
#   nfeat: The number of features that need to be sampled from the dataset
#   m: The number of trees that need to be grown
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c()
for (i in 1:m) {
# Sample  from the rows of x to create a distinct datasets
samples <- sample(x_row, x_row, TRUE)
print(samples)
# Give the samples to tree.grow as the row numbers of the dataset
trees[i] <- tree.grow(samples, y[samples], nmin, minleaf, nfeat)
}
return(trees)
}
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
# Multiple times grows a tree using tree.grow and stores them in a list
#   x_row: The row numbers of the dataset
#   y: The class labels of the dataset
#   nmin: The minimm length of the data in a node to not be a leaf node.
#   minleaf: The minimum number of datapoints that needs to be in a node to not be a leafnode
#   nfeat: The number of features that need to be sampled from the dataset
#   m: The number of trees that need to be grown
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c()
print(x_row)
for (i in 1:m) {
# Sample  from the rows of x to create a distinct datasets
samples <- sample(x_row, x_row, TRUE)
# Give the samples to tree.grow as the row numbers of the dataset
trees[i] <- tree.grow(samples, y[samples], nmin, minleaf, nfeat)
}
return(trees)
}
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
# Multiple times grows a tree using tree.grow and stores them in a list
#   x_row: The row numbers of the dataset
#   y: The class labels of the dataset
#   nmin: The minimm length of the data in a node to not be a leaf node.
#   minleaf: The minimum number of datapoints that needs to be in a node to not be a leafnode
#   nfeat: The number of features that need to be sampled from the dataset
#   m: The number of trees that need to be grown
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c()
for (i in 1:m) {
# Sample  from the rows of x to create a distinct datasets
samples <- sample(length(x_row), length(x_row), TRUE)
# Give the samples to tree.grow as the row numbers of the dataset
trees[i] <- tree.grow(samples, y[samples], nmin, minleaf, nfeat)
}
return(trees)
}
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
print(trees_1[[1]], "splitValue", 'splitAttribute')
# Multiple times grows a tree using tree.grow and stores them in a list
#   x_row: The row numbers of the dataset
#   y: The class labels of the dataset
#   nmin: The minimm length of the data in a node to not be a leaf node.
#   minleaf: The minimum number of datapoints that needs to be in a node to not be a leafnode
#   nfeat: The number of features that need to be sampled from the dataset
#   m: The number of trees that need to be grown
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c()
for (i in 1:m) {
# Sample  from the rows of x to create a distinct datasets
samples <- sample(length(x_row), length(x_row), TRUE)
print(samples)
# Give the samples to tree.grow as the row numbers of the dataset
trees[i] <- tree.grow(samples, y[samples], nmin, minleaf, nfeat)
}
return(trees)
}
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
# Multiple times grows a tree using tree.grow and stores them in a list
#   x_row: The row numbers of the dataset
#   y: The class labels of the dataset
#   nmin: The minimm length of the data in a node to not be a leaf node.
#   minleaf: The minimum number of datapoints that needs to be in a node to not be a leafnode
#   nfeat: The number of features that need to be sampled from the dataset
#   m: The number of trees that need to be grown
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c(1:m)
for (i in 1:m) {
# Sample  from the rows of x to create a distinct datasets
samples <- sample(length(x_row), length(x_row), TRUE)
print(samples)
# Give the samples to tree.grow as the row numbers of the dataset
trees[i] <- tree.grow(samples, y[samples], nmin, minleaf, nfeat)
}
return(trees)
}
# Grow a single tree, since the dataset is global only row numbers ar given to tree.grow
tree_1 <- tree.grow(c(1:nrow(train_data)), train_classes, 15, 5, 41)
# Prints the tree in the correct way
print(tree_1, 'splitValue', "splitAttribute")
predictions_1 <- tree.classify(test_data, tree_1)
measures_1 <- measures(test_classes, predictions_1)
print(measures_1)
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
# Multiple times grows a tree using tree.grow and stores them in a list
#   x_row: The row numbers of the dataset
#   y: The class labels of the dataset
#   nmin: The minimm length of the data in a node to not be a leaf node.
#   minleaf: The minimum number of datapoints that needs to be in a node to not be a leafnode
#   nfeat: The number of features that need to be sampled from the dataset
#   m: The number of trees that need to be grown
tree.grow.bag <- function(x_row, y, nmin, minleaf, nfeat, m) {
trees <- c()
for (i in 1:m) {
# Sample  from the rows of x to create a distinct datasets
samples <- sample(length(x_row), length(x_row), TRUE)
# Give the samples to tree.grow as the row numbers of the dataset
trees <- append(trees, tree.grow(samples, y[samples], nmin, minleaf, nfeat))
}
return(trees)
}
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
print(trees_1[[1]], "splitValue", 'splitAttribute')
predictions_2 <- tree.classify.bag(test_data, trees_1)
# Predicts the class labels for a given dataset and a tree structure
#   data: The dataset that needs to have it's class labels predicted
#   tr: The data.tree structure build by tree.grow
tree.classify <- function(data, tr) {
y <- c(1:100)
for (i in 1:nrow(data)) {
node <- tr
# While the node is not a leaf node, (isLeaf() is a function of data.tree package)
while(!isLeaf(node)) {
# If the value of the data is larger then the split value go to left child if smaller go to right child
print(node$splitAttribute)
if (data[i, node$splitAttribute] > node$splitValue) {
node <- node$leftChild
} else {
node <- node$rightChild
}
}
# Retrieve the class label and store at the corresponding spot in the y vector
y[i] <- node$label
}
return(y)
}
# print(trees_1[[1]], "splitValue", 'splitAttribute')
predictions_2 <- tree.classify.bag(test_data, trees_1)
source('C:/Users/Lisa/Desktop/UU/Data_Mining_2019/Assignment_1_code.R', echo=TRUE)
# Grow trees using random forest and classify
trees_1 <- tree.grow.bag(c(1:nrow(train_data)), train_classes, 15, 5, 41, 100)
# print(trees_1[[1]], "splitValue", 'splitAttribute')
predictions_2 <- tree.classify.bag(test_data, trees_1)
# Predicts the class labels for a given dataset and a tree structure
#   data: The dataset that needs to have it's class labels predicted
#   tr: The data.tree structure build by tree.grow
tree.classify <- function(data, tr) {
y <- c(1:100)
for (i in 1:nrow(data)) {
node <- tr
# While the node is not a leaf node, (isLeaf() is a function of data.tree package)
while(!isLeaf(node)) {
# If the value of the data is larger then the split value go to left child if smaller go to right child
if (data[i, node$splitAttribute] > node$splitValue) {
node <- node$leftChild
} else {
node <- node$rightChild
}
}
# Retrieve the class label and store at the corresponding spot in the y vector
y[i] <- node$label
}
return(y)
}
# print(trees_1[[1]], "splitValue", 'splitAttribute')
predictions_2 <- tree.classify.bag(test_data, trees_1)
measures_2 <- measures(test_classes, predictions_2)
print(measures_2)
print(predictions_2)
print(table(predictions_2, test_classes))
source('C:/Users/Lisa/Desktop/UU/Data_Mining_2019/Assignment_1_code.R', echo=TRUE)
